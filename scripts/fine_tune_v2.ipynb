{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todolist\n",
    "- Gunakan Model yang Lebih Maju\n",
    "- Membersihkan teks dari tanda baca yang tidak perlu atau melakukan tokenisasi yang lebih tepat\n",
    "- Penyaringan atau pemrosesan lanjutan untuk memastikan bahwa jawaban yang dihasilkan relevan dan bermakna\n",
    "- Perluas dataset pelatihan dengan pertanyaan yang lebih bervariasi dan relevan sehingga model memiliki lebih banyak informasi untuk merespons pertanyaan yang mungkin tidak ada dalam dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow pandas transformers datasets tf-keras sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import TFBertForQuestionAnswering, BertTokenizerFast, DefaultDataCollator, create_optimizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress most TensorFlow messages\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure tf_keras is installed\n",
    "try:\n",
    "    import tf_keras\n",
    "except ImportError:\n",
    "    print(\"tf-keras is not installed. Installing now...\")\n",
    "    %pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                            context  \\\n",
      "0   1  ROI atau Return on Investment adalah rasio keu...   \n",
      "1   2  EBITDA atau Earnings Before Interest, Taxes, D...   \n",
      "2   3  Leverage dalam konteks finansial adalah penggu...   \n",
      "3   4  Diversifikasi adalah strategi investasi yang m...   \n",
      "4   5  Volatilitas adalah ukuran seberapa besar harga...   \n",
      "\n",
      "                 question                                             answer  \\\n",
      "0            Apa itu ROI?  ROI atau Return on Investment adalah rasio keu...   \n",
      "1         Apa itu EBITDA?  EBITDA atau Earnings Before Interest, Taxes, D...   \n",
      "2       Apa itu Leverage?  Leverage dalam konteks finansial adalah penggu...   \n",
      "3  Apa itu Diversifikasi?  Diversifikasi adalah strategi investasi yang m...   \n",
      "4    Apa itu Volatilitas?  Volatilitas adalah ukuran seberapa besar harga...   \n",
      "\n",
      "   answer_start  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/final_dataset.csv')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'context', 'question', 'answer', 'answer_start'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model for fine-tuning\n",
    "model_name = \"Rifky/Indobert-QA\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = TFBertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model for generating answers when context is not found\n",
    "pretrained_model = TFBertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=256,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answer\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, (answer, offset) in enumerate(zip(answers, offset_mapping)):\n",
    "        start_char = examples[\"answer_start\"][i]\n",
    "        end_char = start_char + len(answer)\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        context_start = 0\n",
    "        while sequence_ids[context_start] != 1:\n",
    "            context_start += 1\n",
    "        context_end = context_start\n",
    "        while context_end < len(sequence_ids) and sequence_ids[context_end] == 1:\n",
    "            context_end += 1\n",
    "        context_end -= 1\n",
    "\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            start_idx = context_start\n",
    "            while start_idx <= context_end and offset[start_idx][0] <= start_char:\n",
    "                start_idx += 1\n",
    "            start_positions.append(start_idx - 1)\n",
    "\n",
    "            end_idx = context_start\n",
    "            while end_idx <= context_end and offset[end_idx][1] < end_char:\n",
    "                end_idx += 1\n",
    "            end_positions.append(end_idx - 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fba1c06b9224b2f8771c1dc7cceb8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 490\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [3, 2064, 1570, 3057, 939, 35, 4, 3057, 939, 1647, 22739, 2587, 23270, 1581, 10357, 4994, 1647, 5938, 1497, 6023, 1542, 5737, 5646, 1973, 3592, 5737, 18, 3057, 939, 2633, 2318, 1559, 16029, 11311, 1647, 17479, 13163, 2170, 5737, 1647, 1559, 13622, 11311, 1841, 5737, 1497, 2748, 18, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 7, 'end_positions': 25}\n"
     ]
    }
   ],
   "source": [
    "# Check the first few elements\n",
    "for item in tokenized_datasets:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 441\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 49\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the tokenized dataset into train and validation sets\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "val_dataset = train_test_split['test']\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/fine_tuned_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='../logs',\n",
    "    logging_steps=10,\n",
    "    max_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data collator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(tokenized_datasets):\n",
    "    def generator():\n",
    "        for example in tokenized_datasets:\n",
    "            yield (\n",
    "                {\n",
    "                    'input_ids': example['input_ids'],\n",
    "                    'attention_mask': example['attention_mask']\n",
    "                },\n",
    "                {\n",
    "                    'start_positions': example['start_positions'],\n",
    "                    'end_positions': example['end_positions']\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            {\n",
    "                'input_ids': tf.TensorSpec(shape=(256,), dtype=tf.int32),\n",
    "                'attention_mask': tf.TensorSpec(shape=(256,), dtype=tf.int32)\n",
    "            },\n",
    "            {\n",
    "                'start_positions': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                'end_positions': tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "            }\n",
    "        )\n",
    "    ).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_dataset = create_tf_dataset(train_dataset)\n",
    "val_tf_dataset = create_tf_dataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [3, 2064, 1570, 10357, 4392, 7501, 35, 4, 10357, 4392, 7501, 1581, 9740, 1899, 2661, 4392, 1501, 2661, 7501, 18, 10357, 1540, 2318, 1617, 7405, 1559, 16029, 2692, 5646, 1899, 2048, 6706, 6825, 1676, 1501, 2026, 3028, 5737, 18, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 8, 'end_positions': 18}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Batch\n",
      "{'input_ids': [3, 2064, 1570, 4644, 3835, 12517, 35, 4, 4644, 3835, 12517, 1581, 4644, 1497, 8588, 1897, 8003, 1501, 3625, 3835, 12517, 18, 4644, 1540, 23263, 1617, 1990, 1995, 1501, 2318, 1559, 6207, 2050, 1501, 8348, 5958, 18, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_positions': 8, 'end_positions': 20}\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataset.take(1):\n",
    "    print(\"Validation Batch\")\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function infer_framework at 0x0000020936D33310> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1647, in train_step  *\n        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\engine\\compile_utils.py\", line 277, in __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\losses.py\", line 143, in __call__  *\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\losses.py\", line 270, in call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\alifs\\AppData\\Local\\Temp\\ipykernel_11096\\2119429720.py\", line 6, in custom_loss  *\n        y_pred_array = y_pred.numpy()\n\n    AttributeError: 'SymbolicTensor' object has no attribute 'numpy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mtraining_args\u001b[38;5;241m.\u001b[39mlearning_rate),\n\u001b[0;32m     29\u001b[0m               loss\u001b[38;5;241m=\u001b[39mcustom_loss)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tf_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_tf_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_tf_dataset)\n",
      "File \u001b[1;32mc:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1170\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1169\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filez2paqasf.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewt3d8c7k.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m     43\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mjit_compile, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun, (ag__\u001b[38;5;241m.\u001b[39mld(run_step),), \u001b[38;5;28mdict\u001b[39m(args\u001b[38;5;241m=\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(data),)), fscope)\n\u001b[0;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(reduce_per_replica), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_strategy), \u001b[38;5;28mdict\u001b[39m(reduction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_reduction_method), fscope)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewt3d8c7k.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     16\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39mtrain_step, (ag__\u001b[38;5;241m.\u001b[39mld(data),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[0;32m     20\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filek96fmfmq.py:409\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28;01mnonlocal\u001b[39;00m loss\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(loss) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_23, else_body_23, get_state_24, set_state_24, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    410\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28mdict\u001b[39m(tape\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tape)), fscope)\n\u001b[0;32m    411\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mld(y), ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(sample_weight)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filek96fmfmq.py:404\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step.<locals>.if_body_23\u001b[1;34m()\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body_23\u001b[39m():\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m loss\n\u001b[1;32m--> 404\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mregularization_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2bx0y9li.py:203\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    201\u001b[0m continue_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinue_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    202\u001b[0m metric_obj \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_obj\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 203\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), \u001b[38;5;28mtuple\u001b[39m(ag__\u001b[38;5;241m.\u001b[39mld(zip_args)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state_9, set_state_9, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_dim\u001b[39m\u001b[38;5;124m'\u001b[39m,), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(y_t, y_p, sw, loss_obj, loss_weight, metric_obj)\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_10\u001b[39m():\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (regularization_losses,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2bx0y9li.py:193\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.loop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m y_p, y_t, sw, batch_dim\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontinue_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2bx0y9li.py:89\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__.<locals>.loop_body.<locals>.if_body_8\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m (y_t, y_p, sw) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(match_dtype_and_rank), (ag__\u001b[38;5;241m.\u001b[39mld(y_t), ag__\u001b[38;5;241m.\u001b[39mld(y_p), ag__\u001b[38;5;241m.\u001b[39mld(sw)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     88\u001b[0m sw \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(losses_utils)\u001b[38;5;241m.\u001b[39mapply_mask, (ag__\u001b[38;5;241m.\u001b[39mld(y_p), ag__\u001b[38;5;241m.\u001b[39mld(sw), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(losses_utils)\u001b[38;5;241m.\u001b[39mget_mask, (ag__\u001b[38;5;241m.\u001b[39mld(y_p),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 89\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_p\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m total_loss_mean_value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(loss_value)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_2\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileywqdv3f8.py:56\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m     54\u001b[0m call_fn \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_fn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexecuting_eagerly, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_fn\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m losses \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(call_fn), (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     57\u001b[0m in_mask \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(losses_utils)\u001b[38;5;241m.\u001b[39mget_mask, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     58\u001b[0m out_mask \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(losses_utils)\u001b[38;5;241m.\u001b[39mget_mask, (ag__\u001b[38;5;241m.\u001b[39mld(losses),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2daxu7hu.py:38\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ag_fn), (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_fn_kwargs), fscope)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenoeqznu8.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__custom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m y_pred_array \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(y_pred)\u001b[38;5;241m.\u001b[39mnumpy, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m y_true_array \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(y_true)\u001b[38;5;241m.\u001b[39mnumpy, (), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of y_pred:\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(y_pred_array)\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step  *\n        outputs = model.train_step(data)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1647, in train_step  *\n        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\engine\\compile_utils.py\", line 277, in __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\losses.py\", line 143, in __call__  *\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\losses.py\", line 270, in call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\alifs\\AppData\\Local\\Temp\\ipykernel_11096\\2119429720.py\", line 6, in custom_loss  *\n        y_pred_array = y_pred.numpy()\n\n    AttributeError: 'SymbolicTensor' object has no attribute 'numpy'\n"
     ]
    }
   ],
   "source": [
    "# Define custom loss function\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    y_pred_array = y_pred.numpy()\n",
    "    y_true_array = y_true.numpy()\n",
    "\n",
    "    # Melihat bentuk array\n",
    "    print(\"Shape of y_pred:\", y_pred_array.shape)\n",
    "    print(\"Shape of y_true:\", y_true_array.shape)\n",
    "    \n",
    "    start_positions = tf.gather(tf.reshape(y_pred[0], [-1, tf.shape(y_pred[0])[-1]]), y_true[:, 0], batch_dims=1)\n",
    "    end_positions = tf.gather(tf.reshape(y_pred[1], [-1, tf.shape(y_pred[1])[-1]]), y_true[:, 1], batch_dims=1)\n",
    "    \n",
    "    start_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true[:, 0], start_positions, from_logits=True\n",
    "    )\n",
    "    \n",
    "    end_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true[:, 1], end_positions, from_logits=True\n",
    "    )\n",
    "    \n",
    "    return (start_loss + end_loss) / 2.0\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=training_args.learning_rate),\n",
    "              loss=custom_loss)\n",
    "model.fit(train_tf_dataset, validation_data=val_tf_dataset, epochs=training_args.num_train_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(val_tf_dataset)\n",
    "print(f\"Validation loss: {results}\")\n",
    "\n",
    "# Predict and visualize the results\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(val_tf_dataset)\n",
    "\n",
    "# Extracting predicted start and end positions from the model's output\n",
    "predicted_start_positions = tf.argmax(predictions[0], axis=-1)\n",
    "predicted_end_positions = tf.argmax(predictions[1], axis=-1)\n",
    "\n",
    "# Convert tensors to numpy arrays for confusion matrix plotting\n",
    "predicted_start_positions = predicted_start_positions.numpy()\n",
    "predicted_end_positions = predicted_end_positions.numpy()\n",
    "\n",
    "# Get true start and end positions\n",
    "true_start_positions = val_dataset[\"start_positions\"]\n",
    "true_end_positions = val_dataset[\"end_positions\"]\n",
    "\n",
    "# Ensure matching lengths\n",
    "true_start_positions = true_start_positions[:len(predicted_start_positions)]\n",
    "true_end_positions = true_end_positions[:len(predicted_end_positions)]\n",
    "\n",
    "# Plot confusion matrix for start positions\n",
    "plot_confusion_matrix(true_start_positions, predicted_start_positions, labels=list(range(len(tokenizer))))\n",
    "\n",
    "# Plot confusion matrix for end positions\n",
    "plot_confusion_matrix(true_end_positions, predicted_end_positions, labels=list(range(len(tokenizer))))\n",
    "\n",
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    tf.print('y_true:', y_true)\n",
    "    tf.print('y_pred:', y_pred)\n",
    "    \n",
    "    y_true_start, y_true_end = y_true\n",
    "    y_pred_start, y_pred_end = y_pred\n",
    "\n",
    "    tf.print('y_true_start shape:', tf.shape(y_true_start))\n",
    "    tf.print('y_true_end shape:', tf.shape(y_true_end))\n",
    "    tf.print('y_pred_start shape:', tf.shape(y_pred_start))\n",
    "    tf.print('y_pred_end shape:', tf.shape(y_pred_end))\n",
    "    \n",
    "    start_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_start, y_pred_start, from_logits=True)\n",
    "    end_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true_end, y_pred_end, from_logits=True)\n",
    "\n",
    "    \n",
    "    return (start_loss + end_loss) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_start_logits_accuracy(y_true, y_pred):\n",
    "    y_true_start, _ = y_true\n",
    "    y_pred_start, _ = y_pred\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true_start, y_pred_start)\n",
    "\n",
    "def compute_end_logits_accuracy(y_true, y_pred):\n",
    "    _, y_true_end = y_true\n",
    "    _, y_pred_end = y_pred\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true_end, y_pred_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer and compile model\n",
    "num_train_steps = len(train_dataset) * training_args.num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=training_args.learning_rate,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=training_args.weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with the correct metrics\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=custom_loss,\n",
    "              metrics={\n",
    "                  'start_logits_accuracy': compute_start_logits_accuracy,\n",
    "                  'end_logits_accuracy': compute_end_logits_accuracy\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks for logging accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LossAccuracyF1Logger(tf.keras.callbacks.Callback):\n",
    "#     def __init__(self, validation_data):\n",
    "#         super(LossAccuracyF1Logger, self).__init__()\n",
    "#         self.validation_data = validation_data\n",
    "#         self.epoch_loss = []\n",
    "#         self.epoch_start_accuracy = []\n",
    "#         self.epoch_end_accuracy = []\n",
    "#         self.epoch_f1 = []\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         self.epoch_loss.append(logs['loss'])\n",
    "#         self.epoch_start_accuracy.append(logs['start_logits_accuracy'])\n",
    "#         self.epoch_end_accuracy.append(logs['end_logits_accuracy'])\n",
    "        \n",
    "#         # Calculate F1 score on validation data\n",
    "#         predictions, true_labels = [], []\n",
    "#         for batch in self.validation_data:\n",
    "#             inputs = {'input_ids': batch['input_ids'], 'attention_mask': batch['attention_mask']}\n",
    "#             true_labels.extend(batch['start_positions'].numpy())\n",
    "#             start_logits, end_logits = self.model.predict(inputs)\n",
    "#             pred_start = tf.argmax(start_logits, axis=-1).numpy()\n",
    "#             pred_end = tf.argmax(end_logits, axis=-1).numpy()\n",
    "#             predictions.extend(pred_start)\n",
    "        \n",
    "#         f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "#         self.epoch_f1.append(f1)\n",
    "        \n",
    "#         # Plot the metrics\n",
    "#         self.plot()\n",
    "        \n",
    "#     def plot(self):\n",
    "#         plt.figure(figsize=(18, 5))\n",
    "#         plt.subplot(1, 4, 1)\n",
    "#         plt.plot(self.epoch_loss, label='Loss')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.legend()\n",
    "#         plt.subplot(1, 4, 2)\n",
    "#         plt.plot(self.epoch_start_accuracy, label='Start Accuracy')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         plt.ylabel('Start Accuracy')\n",
    "#         plt.legend()\n",
    "#         plt.subplot(1, 4, 3)\n",
    "#         plt.plot(self.epoch_end_accuracy, label='End Accuracy')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         plt.ylabel('End Accuracy')\n",
    "#         plt.legend()\n",
    "#         plt.subplot(1, 4, 4)\n",
    "#         plt.plot(self.epoch_f1, label='F1 Score')\n",
    "#         plt.xlabel('Epoch')\n",
    "#         plt.ylabel('F1 Score')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        \n",
    "#     def _implements_train_batch_hooks(self):\n",
    "#         return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossAccuracyLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(LossAccuracyLogger, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.epoch_loss = []\n",
    "        self.epoch_start_accuracy = []\n",
    "        self.epoch_end_accuracy = []\n",
    "        self.val_loss = []\n",
    "        self.val_start_accuracy = []\n",
    "        self.val_end_accuracy = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_loss.append(logs['loss'])\n",
    "        self.epoch_start_accuracy.append(logs['start_logits_accuracy'])\n",
    "        self.epoch_end_accuracy.append(logs['end_logits_accuracy'])\n",
    "\n",
    "        val_loss, val_start_accuracy, val_end_accuracy = self.evaluate_validation()\n",
    "        self.val_loss.append(val_loss)\n",
    "        self.val_start_accuracy.append(val_start_accuracy)\n",
    "        self.val_end_accuracy.append(val_end_accuracy)\n",
    "\n",
    "        self.plot_metrics()\n",
    "\n",
    "    def evaluate_validation(self):\n",
    "        val_loss = 0\n",
    "        val_start_accuracy = 0\n",
    "        val_end_accuracy = 0\n",
    "        for batch in self.validation_data:\n",
    "            inputs = {'input_ids': batch[0]['input_ids'], 'attention_mask': batch[0]['attention_mask']}\n",
    "            start_positions, end_positions = batch[1]\n",
    "\n",
    "            loss = self.model.evaluate(inputs, batch[1], verbose=0)\n",
    "            val_loss += loss[0]\n",
    "            val_start_accuracy += loss[1]\n",
    "            val_end_accuracy += loss[2]\n",
    "\n",
    "        val_loss /= len(self.validation_data)\n",
    "        val_start_accuracy /= len(self.validation_data)\n",
    "        val_end_accuracy /= len(self.validation_data)\n",
    "        return val_loss, val_start_accuracy, val_end_accuracy\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        plt.figure(figsize=(18, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.epoch_loss, label='Training Loss')\n",
    "        plt.plot(self.val_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Learning Curve - Loss')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.epoch_start_accuracy, label='Training Start Accuracy')\n",
    "        plt.plot(self.val_start_accuracy, label='Validation Start Accuracy')\n",
    "        plt.plot(self.epoch_end_accuracy, label='Training End Accuracy')\n",
    "        plt.plot(self.val_end_accuracy, label='Validation End Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Learning Curve - Accuracy')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch in self.validation_data:\n",
    "            inputs = {'input_ids': batch[0]['input_ids'], 'attention_mask': batch[0]['attention_mask']}\n",
    "            true_start, true_end = batch[1]\n",
    "            start_logits, end_logits = model.predict(inputs)\n",
    "            pred_start = tf.argmax(start_logits, axis=-1).numpy()\n",
    "            pred_end = tf.argmax(end_logits, axis=-1).numpy()\n",
    "            y_true.extend(true_start.numpy())\n",
    "            y_true.extend(true_end.numpy())\n",
    "            y_pred.extend(pred_start)\n",
    "            y_pred.extend(pred_end)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan experimental.gpu_options untuk mengatur pertumbuhan memori GPU\n",
    "# import tensorflow as tf\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Hanya alokasi memori yang diperlukan\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LossAccuracyLogger(validation_data=val_tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mixed precision policy and enable eager execution\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [[13]\n",
      " [7]\n",
      " [13]\n",
      " [8]]\n",
      "y_pred: [[-8.35542 -9.20482159 -9.25583267 ... -10.4150944 -9.50561333 -9.41956902]\n",
      " [-9.88490868 -9.41079426 -9.99605656 ... -9.8761549 -9.54917049 -9.99579811]\n",
      " [-7.74446583 -9.316679 -9.77689838 ... -10.3791056 -10.2641125 -9.57383728]\n",
      " [-9.57224274 -9.36782265 -9.32917213 ... -9.96795368 -9.62810898 -9.99006271]]\n",
      "An error occurred during training: in user code:\n",
      "\n",
      "    File \"C:\\Users\\alifs\\AppData\\Local\\Temp\\ipykernel_5132\\1234561693.py\", line 5, in custom_loss  *\n",
      "        y_true_start, y_true_end = y_true\n",
      "\n",
      "    ValueError: too many values to unpack (expected 2)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\alifs\\AppData\\Local\\Temp\\ipykernel_5132\\1234561693.py\", line 5, in custom_loss  *\n        y_true_start, y_true_end = y_true\n\n    ValueError: too many values to unpack (expected 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tf_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred during training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1170\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1169\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\alifs\\anaconda3\\envs\\main-ds\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1647\u001b[0m, in \u001b[0;36mTFPreTrainedModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1644\u001b[0m             y_pred \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1647\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filembsarhk7.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__custom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mprint, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true:\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(y_true)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mprint, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred:\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 12\u001b[0m (y_true_start, y_true_end) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_true)\n\u001b[0;32m     13\u001b[0m (y_pred_start, y_pred_end) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_pred)\n\u001b[0;32m     14\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mprint, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true_start shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mshape, (ag__\u001b[38;5;241m.\u001b[39mld(y_true_start),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\alifs\\AppData\\Local\\Temp\\ipykernel_5132\\1234561693.py\", line 5, in custom_loss  *\n        y_true_start, y_true_end = y_true\n\n    ValueError: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(train_tf_dataset, epochs=training_args.num_train_epochs, callbacks=[logger])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cek nilai null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periksa Data Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada nilai None dalam data input.\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# Periksa apakah ada nilai None dalam data input\n",
    "def check_for_none(batch):\n",
    "    for key, value in batch.items():\n",
    "        if value is None:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Gunakan reduce untuk menggabungkan hasil dari setiap batch menjadi satu nilai boolean\n",
    "has_none = reduce(lambda x, y: x or y, train_dataset.map(check_for_none))\n",
    "\n",
    "if has_none:\n",
    "    print(\"Ada nilai None dalam data input.\")\n",
    "else:\n",
    "    print(\"Tidak ada nilai None dalam data input.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periksa Kembali Proses Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"tf_bert_for_question_answering_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109967616 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109969154 (419.50 MB)\n",
      "Trainable params: 109969154 (419.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Daftar metrik yang didefinisikan untuk model:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model summary:\")\n",
    "print(model.summary())\n",
    "\n",
    "# Periksa definisi metrik\n",
    "print(\"Daftar metrik yang didefinisikan untuk model:\")\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periksa Definisi Model dan Metrik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model telah diinisialisasi.\n",
      "Semua metrik telah diinisialisasi dengan benar.\n"
     ]
    }
   ],
   "source": [
    "# Pastikan model telah diinisialisasi dengan benar\n",
    "if model is None:\n",
    "    print(\"Model belum diinisialisasi dengan benar.\")\n",
    "else:\n",
    "    print(\"Model telah diinisialisasi.\")\n",
    "\n",
    "# Pastikan metrik telah diinisialisasi dengan benar\n",
    "if any(metric is None for metric in [compute_start_logits_accuracy, compute_end_logits_accuracy]):\n",
    "    print(\"Ada metrik yang belum diinisialisasi dengan benar.\")\n",
    "else:\n",
    "    print(\"Semua metrik telah diinisialisasi dengan benar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periksa Proses Pembelajaran:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terjadi kesalahan saat memeriksa gradien: module 'keras._tf_keras.keras.backend' has no attribute 'compute_gradients'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gradients = tf.keras.backend.compute_gradients(model.loss, model.trainable_variables)\n",
    "    if any(grad is None for grad, _ in gradients):\n",
    "        print(\"Ada masalah dalam proses pembelajaran: beberapa parameter tidak memiliki gradien.\")\n",
    "    else:\n",
    "        print(\"Proses pembelajaran berjalan dengan baik: semua parameter memiliki gradien.\")\n",
    "except Exception as e:\n",
    "    print(\"Terjadi kesalahan saat memeriksa gradien:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "# for example in train_dataset:\n",
    "#     input_ids = tf.convert_to_tensor([example['input_ids']])\n",
    "#     attention_mask = tf.convert_to_tensor([example['attention_mask']])\n",
    "#     # Hapus pemanggilan model di sini\n",
    "#     start_logits, end_logits = model(input_ids=input_ids, attention_mask=attention_mask, training=False)\n",
    "#     start_index = tf.argmax(start_logits, axis=-1)[0].numpy()\n",
    "#     end_index = tf.argmax(end_logits, axis=-1)[0].numpy()\n",
    "#     predicted_answer = tokenizer.decode(input_ids[0][start_index:end_index + 1])\n",
    "#     true_answer = example['answer']\n",
    "#     # Hanya cetak hasil prediksi di sini\n",
    "#     if predicted_answer != true_answer:\n",
    "#         print(\"Question:\", example['question'])\n",
    "#         print(\"Predicted Answer:\", predicted_answer)\n",
    "#         print(\"True Answer:\", true_answer)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accuracy, loss, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to answer a question using the fine-tuned model or the pretrained model\n",
    "def answer_question(question, context, use_pretrained=False):\n",
    "    if context is None:\n",
    "        use_pretrained = True  # Use pretrained model if context is not available\n",
    "    inputs = tokenizer(question, context, return_tensors=\"tf\")\n",
    "    if use_pretrained:\n",
    "        outputs = pretrained_model(inputs)\n",
    "    else:\n",
    "        outputs = model(inputs)\n",
    "    answer_start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
    "    answer_end = tf.argmax(outputs.end_logits, axis=1).numpy()[0] + 1\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find context based on the question using Jaccard similarity\n",
    "def find_context_for_question(question, dataframe):\n",
    "    max_matched_words = 0\n",
    "    best_matched_context = None\n",
    "    context_found = False\n",
    "\n",
    "    # Iterate through the rows of the dataframe\n",
    "    for _, row in dataframe.iterrows():\n",
    "        if question.strip().lower() in row['question'].strip().lower():\n",
    "            best_matched_context = row['context']\n",
    "            context_found = True\n",
    "            break  # Break the loop if a matching context is found\n",
    "\n",
    "    # If no exact match is found, find the best matching context based on the number of common words\n",
    "    if not context_found:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            dataset_tokens = set(row['question'].strip().lower().split())\n",
    "            matched_words = len(set(question.strip().lower().split()).intersection(dataset_tokens))\n",
    "            if matched_words > max_matched_words:\n",
    "                max_matched_words = matched_words\n",
    "                best_matched_context = row['context']\n",
    "\n",
    "    return best_matched_context, context_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to provide a recommendation when no answer is found in the dataset\n",
    "def provide_recommendation():\n",
    "    return (\"Terima kasih atas pertanyaannya! Meskipun tidak ada jawaban langsung dari kami, berikut adalah \"\n",
    "            \"beberapa rekomendasi umum untuk membantu keuangan anda:\\n\\n\"\n",
    "            \"1. Mulailah dengan membuat anggaran dan mengelola pengeluaran Anda dengan cermat.\\n\"\n",
    "            \"2. Pertimbangkan untuk mencari peluang sampingan atau pekerjaan paruh waktu.\\n\"\n",
    "            \"3. Pelajari dan investasikan uang Anda dengan bijak. Mungkin Anda ingin mempertimbangkan untuk berinvestasi dalam saham, obligasi, atau properti.\\n\"\n",
    "            \"4. Kembangkan keterampilan yang bernilai tinggi dan pertimbangkan untuk memonetisasi hobi atau minat Anda.\\n\"\n",
    "            \"5. Jangan lupa untuk memiliki perencanaan keuangan jangka panjang, termasuk perencanaan pensiun dan perlindungan asuransi.\\n\\n\"\n",
    "            \"Semoga ini membantu Anda memulai perjalanan keuangan Anda!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input for the question\n",
    "# user_question = input(\"Enter your financial question: \")\n",
    "# user_question = \"Apa itu EBITDA\"\n",
    "user_question = \"apa nama ibu kota indonesia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find context for the user's question\n",
    "# context = find_context_for_question(user_question, df)\n",
    "context, context_found = find_context_for_question(user_question, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find context based on the question\n",
    "# Mendekati dataset\n",
    "# Tidak disarankan karena halusinasi\n",
    "\n",
    "def provide_recommendation_for_question(question):\n",
    "    max_matched_words = 0\n",
    "    best_matched_context = None\n",
    "\n",
    "    # Iterate through the rows of the dataset\n",
    "    for _, row in df.iterrows():\n",
    "        dataset_tokens = set(row['question'].strip().lower().split())\n",
    "        matched_words = len(set(question.strip().lower().split()).intersection(dataset_tokens))\n",
    "        if matched_words > max_matched_words:\n",
    "            max_matched_words = matched_words\n",
    "            best_matched_context = row['context']\n",
    "\n",
    "    if best_matched_context:\n",
    "        return best_matched_context\n",
    "    else:\n",
    "        return provide_recommendation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: apa nama ibu kota indonesia\n",
      "A: Investasi pemerintah dalam proyek pembangunan ibu kota baru mencapai Rp150 triliun pada tahun 2023.\n"
     ]
    }
   ],
   "source": [
    "if context_found:\n",
    "    # Get the answer to the user question using the found context\n",
    "    answer = answer_question(user_question, context)\n",
    "    print(f\"Q: {user_question}\\nA: {answer}\")\n",
    "else:\n",
    "    # If context is not found, provide a recommendation based on the user's question\n",
    "    answer = provide_recommendation_for_question(user_question)\n",
    "    print(f\"Q: {user_question}\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model at the end\n",
    "# model.save_pretrained(\"../models/fine_tuned_model\")\n",
    "# tokenizer.save_pretrained(\"../models/fine_tuned_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
