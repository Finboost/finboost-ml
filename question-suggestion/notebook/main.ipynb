{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Suggestion Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara memilih reksadana dengan biaya ...</td>\n",
       "      <td>Reksadana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apa itu reksadana terbuka dan bagaimana cara k...</td>\n",
       "      <td>Reksadana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bagaimana cara keluar dari investasi reksadana?</td>\n",
       "      <td>Reksadana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apa saja faktor yang mempengaruhi nilai aset b...</td>\n",
       "      <td>Reksadana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apa itu reksadana offshore dan bagaimana cara ...</td>\n",
       "      <td>Reksadana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question   Category\n",
       "0  Bagaimana cara memilih reksadana dengan biaya ...  Reksadana\n",
       "1  Apa itu reksadana terbuka dan bagaimana cara k...  Reksadana\n",
       "2    Bagaimana cara keluar dari investasi reksadana?  Reksadana\n",
       "3  Apa saja faktor yang mempengaruhi nilai aset b...  Reksadana\n",
       "4  Apa itu reksadana offshore dan bagaimana cara ...  Reksadana"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../dataset/example_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions: ['Bagaimana cara memilih reksadana dengan biaya rendah?', 'Apa itu reksadana terbuka dan bagaimana cara kerjanya?', 'Bagaimana cara keluar dari investasi reksadana?', 'Apa saja faktor yang mempengaruhi nilai aset bersih reksadana?', 'Apa itu reksadana offshore dan bagaimana cara berinvestasi di dalamnya?']\n",
      "labels: ['Reksadana', 'Reksadana', 'Reksadana', 'Reksadana', 'Reksadana']\n"
     ]
    }
   ],
   "source": [
    "# Separate questions and labels\n",
    "questions = df['Question'].tolist()\n",
    "labels = df['Category'].tolist()\n",
    "\n",
    "print(f'questions: {questions[:5]}')\n",
    "print(f'labels: {labels[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_dict: {'Cryptocurrency': 0, 'Pajak': 1, 'Obligasi': 2, 'Reksadana': 3, 'Saham': 4, 'Manajemen keuangan pribadi': 5, 'Makro ekonomi': 6, 'Emas': 7, 'Asuransi': 8}\n",
      "numerical_labels: [3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Convert categories to numerical labels\n",
    "label_dict = {label: idx for idx, label in enumerate(set(labels))}\n",
    "numerical_labels = [label_dict[label] for label in labels]\n",
    "\n",
    "print(f'label_dict: {label_dict}')\n",
    "print(f'numerical_labels: {numerical_labels[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(questions)\n",
    "sequences = tokenizer.texts_to_sequences(questions)\n",
    "padded_sequences = pad_sequences(sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.legacy.preprocessing.text.Tokenizer object at 0x000001221E1B6050>\n",
      "{'bagaimana': 1, 'cara': 2, 'apa': 3, 'dan': 4, 'itu': 5, 'dalam': 6, 'saja': 7, 'reksadana': 8, 'yang': 9, 'obligasi': 10, 'emas': 11, 'saham': 12, 'dengan': 13, 'berinvestasi': 14, 'pajak': 15, 'untuk': 16, 'asuransi': 17, 'investasi': 18, 'cryptocurrency': 19, 'memilih': 20, 'kerjanya': 21, 'di': 22, 'dimaksud': 23, 'memahami': 24, 'menggunakan': 25, 'dari': 26, 'menghitung': 27, 'keuntungan': 28, 'trading': 29, 'faktor': 30, 'mempengaruhi': 31, 'dalamnya': 32, 'memanfaatkan': 33, 'analisis': 34, 'terhadap': 35, 'keuangan': 36, 'mengelola': 37, 'perbedaan': 38, 'antara': 39, 'jenis': 40, 'risiko': 41, 'risikonya': 42, 'perdagangan': 43, 'melakukan': 44, 'menggunakannya': 45, 'harga': 46, 'pasar': 47, 'menghindari': 48, 'pengaruhnya': 49, 'rendah': 50, 'nilai': 51, 'penyertaan': 52, 'keuntungannya': 53, 'sesuai': 54, 'leverage': 55, 'perusahaan': 56, 'terdaftar': 57, 'sertifikat': 58, 'perhiasan': 59, 'aman': 60, 'kelebihan': 61, 'digital': 62, 'membeli': 63, 'platform': 64, 'secara': 65, 'menilainya': 66, 'membuat': 67, 'saat': 68, 'tips': 69, 'tepat': 70, 'langkah': 71, 'anggaran': 72, 'fund': 73, 'utang': 74, 'jiwa': 75, 'polis': 76, 'mengajukan': 77, 'ekonomi': 78, 'laporan': 79, 'negara': 80, 'kebijakan': 81, 'perekonomian': 82, 'pelaporan': 83, 'penghasilan': 84, 'tax': 85, 'melakukannya': 86, 'melaporkan': 87, 'portofolio': 88, 'biaya': 89, 'terbuka': 90, 'keluar': 91, 'aset': 92, 'bersih': 93, 'offshore': 94, 'return': 95, 'on': 96, 'investment': 97, 'roi': 98, 'switching': 99, 'konvensional': 100, 'syariah': 101, 'fasilitas': 102, 'auto': 103, 'invest': 104, 'unit': 105, 'perpetual': 106, 'hijau': 107, 'floating': 108, 'rate': 109, 'notes': 110, 'frn': 111, 'menilai': 112, 'likuiditas': 113, 'terkait': 114, 'prospektus': 115, 'euro': 116, 'perencanaan': 117, 'korporasi': 118, 'junk': 119, 'profil': 120, 'defensif': 121, 'kapan': 122, 'sebaiknya': 123, 'volatilitas': 124, 'ipo': 125, 'berpartisipasi': 126, 'candlestick': 127, 'chart': 128, 'swot': 129, 'tidak': 130, 'dividen': 131, 'beta': 132, 'sektor': 133, 'batangan': 134, 'putih': 135, 'menyimpan': 136, 'fisik': 137, 'kekurangan': 138, 'antam': 139, 'membelinya': 140, 'pegadaian': 141, 'global': 142, 'staking': 143, 'mengenali': 144, 'proyek': 145, 'menjanjikan': 146, 'teknik': 147, 'dasar': 148, 'teknikal': 149, 'tokenomics': 150, 'decentralized': 151, 'exchange': 152, 'dex': 153, 'fork': 154, 'konteks': 155, 'hardware': 156, 'wallet': 157, 'scam': 158, 'rencana': 159, 'pribadi': 160, 'rasio': 161, 'tabungan': 162, 'meningkatkannya': 163, 'menghadapi': 164, 'phk': 165, 'mengurangi': 166, 'pengeluaran': 167, 'harian': 168, 'menyiapkan': 169, 'dana': 170, 'pensiun': 171, 'bulanan': 172, 'mengatur': 173, 'prioritas': 174, 'keluarga': 175, 'sinking': 176, 'pendidikan': 177, 'anak': 178, 'berlebihan': 179, 'kesehatan': 180, 'mendapatkan': 181, 'premi': 182, 'lebih': 183, 'deductible': 184, 'kendaraan': 185, 'manfaat': 186, 'perjalanan': 187, 'ketentuan': 188, 'cash': 189, 'value': 190, 'klaim': 191, 'underwriting': 192, 'indikator': 193, 'penting': 194, 'diperhatikan': 195, 'membaca': 196, 'makro': 197, 'surplus': 198, 'mengatasi': 199, 'defisit': 200, 'tukar': 201, 'mata': 202, 'uang': 203, 'moneter': 204, 'inflasi': 205, 'dampak': 206, 'fiskal': 207, 'publik': 208, 'quantitative': 209, 'easing': 210, 'pengaruh': 211, 'suku': 212, 'bunga': 213, 'negatif': 214, 'dokumen': 215, 'diperlukan': 216, 'tambahan': 217, 'pengurangan': 218, 'tersedia': 219, 'denda': 220, 'planning': 221, 'bisnis': 222, 'kecil': 223, 'berganda': 224, 'menghindarinya': 225, 'keringanan': 226, 'amnesty': 227, 'bagi': 228, 'wajib': 229, 'luar': 230, 'negeri': 231, 'online': 232, 'tematik': 233, 'mengevaluasi': 234, 'kinerja': 235, 'feeder': 236, 'optimal': 237, 'redemption': 238, 'perlu': 239, 'dipertimbangkan': 240, 'total': 241, 'expense': 242, 'ratio': 243, 'terbatas': 244, 'internasional': 245, 'money': 246, 'market': 247, 'surat': 248, 'pernyataan': 249, 'penawaran': 250, 'konversi': 251, 'menentukan': 252, 'seri': 253, 'melalui': 254, 'sekunder': 255, 'tetap': 256, 'mengambang': 257, 'diversifikasi': 258, 'callable': 259, 'bonds': 260, 'yield': 261, 'spread': 262, 'tanpa': 263, 'jaminan': 264, 'moving': 265, 'average': 266, 'convergence': 267, 'divergence': 268, 'macd': 269, 'bollinger': 270, 'bands': 271, 'short': 272, 'selling': 273, 'pivot': 274, 'points': 275, 'spekulatif': 276, 'tahunan': 277, 'likuid': 278, 'teknologi': 279, 'stock': 280, 'buyback': 281, 'stochastic': 282, 'oscillator': 283, 'sebagai': 284, 'jangka': 285, 'pendek': 286, 'etf': 287, 'kontrak': 288, 'berjangka': 289}\n",
      "[[1, 2, 20, 8, 13, 89, 50], [3, 5, 8, 90, 4, 1, 2, 21], [1, 2, 91, 26, 18, 8], [3, 7, 30, 9, 31, 51, 92, 93, 8], [3, 5, 8, 94, 4, 1, 2, 14, 22, 32]]\n",
      "[[ 1  2 20  8 13 89 50  0  0  0  0]\n",
      " [ 3  5  8 90  4  1  2 21  0  0  0]\n",
      " [ 1  2 91 26 18  8  0  0  0  0  0]\n",
      " [ 3  7 30  9 31 51 92 93  8  0  0]\n",
      " [ 3  5  8 94  4  1  2 14 22 32  0]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)\n",
    "print(tokenizer.word_index)\n",
    "print(sequences[:5])\n",
    "print(padded_sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_labels: [3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Convert numerical labels to a numpy array\n",
    "numerical_labels = np.array(numerical_labels)\n",
    "print(f'numerical_labels: {numerical_labels[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (101, 11)\n",
      "X_val: (26, 11)\n",
      "y_train: (101,)\n",
      "y_val: (26,)\n",
      "X_train: [[  1   2  77 191  17  75   0   0   0   0   0]\n",
      " [  3   5 192   6  17   0   0   0   0   0   0]\n",
      " [  3   9  23  13 108 109 110 111   0   0   0]\n",
      " [  1   2 144 145  19   9 146   0   0   0   0]\n",
      " [  3   5  58  11   4   1   2  45   0   0   0]]\n",
      "X_val: [[  3   9  23  13  12  57   4 130  57   0   0]\n",
      " [  3   5 265 266 267 268 269   0   0   0   0]\n",
      " [  1   2  27  15  84 217   0   0   0   0   0]\n",
      " [  3   7  71  71   6  67  72 172   0   0   0]\n",
      " [  1   2  44  29  19  65  60   0   0   0   0]]\n",
      "y_train: [8 8 2 0 7]\n",
      "y_val: [4 4 1 5 0]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, numerical_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_val: {X_val.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_val: {y_val.shape}')\n",
    "\n",
    "print(f'X_train: {X_train[:5]}')\n",
    "print(f'X_val: {X_val[:5]}')\n",
    "print(f'y_train: {y_train[:5]}')\n",
    "print(f'y_val: {y_val[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique categories: 9\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(labels))\n",
    "print(f'Number of unique categories: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.1069 - loss: 2.1975 - val_accuracy: 0.1538 - val_loss: 2.1897\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2700 - loss: 2.1869 - val_accuracy: 0.1154 - val_loss: 2.1839\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2338 - loss: 2.1748 - val_accuracy: 0.1538 - val_loss: 2.1744\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3067 - loss: 2.1615 - val_accuracy: 0.2692 - val_loss: 2.1618\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2957 - loss: 2.1399 - val_accuracy: 0.2692 - val_loss: 2.1449\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2859 - loss: 2.1108 - val_accuracy: 0.2692 - val_loss: 2.1204\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3330 - loss: 2.0662 - val_accuracy: 0.3462 - val_loss: 2.0825\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4015 - loss: 2.0001 - val_accuracy: 0.3846 - val_loss: 2.0315\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4257 - loss: 1.9158 - val_accuracy: 0.3846 - val_loss: 1.9579\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4693 - loss: 1.7650 - val_accuracy: 0.4231 - val_loss: 1.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x122093014d0>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "Top category and with the probability:\n",
      "Obligasi: 0.2018\n",
      "Suggested questions:\n",
      "Apa itu obligasi perpetual dan apa keuntungannya?\n",
      "Bagaimana cara berinvestasi dalam obligasi hijau?\n",
      "Apa yang dimaksud dengan floating rate notes (FRN)?\n",
      "Bagaimana cara menilai likuiditas obligasi?\n"
     ]
    }
   ],
   "source": [
    "# Function to predict top questions\n",
    "def suggest_questions(user_input, total_questions=4):\n",
    "    sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=padded_sequences.shape[1], padding='post')\n",
    "    predictions = model.predict(padded_sequence)\n",
    "    labels = list(label_dict.keys())\n",
    "    \n",
    "    # Get top n categories with their probabilities\n",
    "    top_categories_prediction = np.argsort(predictions[0])[-1:][::-1]\n",
    "    top_categories = [(labels[idx], predictions[0][idx]) for idx in top_categories_prediction]\n",
    "    \n",
    "    # Print top categories with their probabilities\n",
    "    print(\"Top category and with the probability:\")\n",
    "    for category, prob in top_categories:\n",
    "        print(f'{category}: {prob:.4f}')\n",
    "    \n",
    "    # Filter questions from the dataset based on top categories\n",
    "    suggested_questions = []\n",
    "    for category, _ in top_categories:\n",
    "        category_questions = df[df['Category'] == category]['Question'].tolist()\n",
    "        suggested_questions.extend(category_questions)\n",
    "    \n",
    "    # You can choose to return a random selection of questions, limit the number, etc.\n",
    "    return suggested_questions[:total_questions]\n",
    "\n",
    "# Example usage\n",
    "user_input = \"Bagaimana cara berinvestasi yang aman?\"\n",
    "# user_input = \"Bagaimana cara memilih asuransi yang tepat?\"\n",
    "# user_input = \"Bagaimana cara memilih saham yang baik?\"\n",
    "# user_input = \"Bagaimana cara membuat anggaran bulanan yang efektif?\"\n",
    "# user_input = \"Apa itu cryptocurrency?\"\n",
    "# user_input = \"Apa yang harus saya lakukan jika suku bunga naik?\"\n",
    "# user_input = \"Bagaimana cara saya memilih reksadana?\"\n",
    "# user_input = \"Bagaimana cara saya memilih reksadana yang baik?\"\n",
    "\n",
    "# user_input = \"Apa yang dimaksud dengan premi dalam asuransi?\"\n",
    "\n",
    "\n",
    "suggested_questions = suggest_questions(user_input)\n",
    "print(\"Suggested questions:\")\n",
    "for question in suggested_questions:\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
