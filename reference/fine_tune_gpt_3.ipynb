{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_WsEOQfGjoXo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WsEOQfGjoXo",
        "outputId": "09caf8ad-0b57-42db-e4da-f07d0541bcc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56483e72",
      "metadata": {
        "id": "56483e72"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f27d4ed",
      "metadata": {
        "id": "3f27d4ed"
      },
      "source": [
        "# How to fine-tune a GPT-3 model for specific prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b56a7b0",
      "metadata": {
        "id": "6b56a7b0"
      },
      "source": [
        "I'm constantly looking for ways to automate the work with support requests. An idea has been to fine-tune a GPT-3 model to answer common support-related questions.\n",
        "\n",
        "**Here's how you can fine-tune a GPT-3 model with Python with your own data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f831ab",
      "metadata": {
        "id": "a2f831ab"
      },
      "source": [
        "In this walkthrough, we'll fine-tune a GPT-3 model to answer common support-related questions.\n",
        "\n",
        "Detailed step-by-step intructions for this repo in this blog post: https://norahsakal.com/blog/fine-tune-gpt3-model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b102018b",
      "metadata": {
        "id": "b102018b"
      },
      "source": [
        ">### Disclaimer\n",
        ">This guide walks you through fine-tuning a GPT-3 model in Python, shown in a Jupyter notebook.\n",
        ">If you're looking for the steps of fine-tuning right in a terminal, [OpenAI has a great guide for fine-tuning in your terminal](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning in terminal\")."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "698f669e",
      "metadata": {
        "id": "698f669e"
      },
      "source": [
        "# Define OpenAI API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcaff120",
      "metadata": {
        "id": "dcaff120"
      },
      "outputs": [],
      "source": [
        "# Ganti API_Key nya, jangan pake API_Key kuuðŸ˜¤\n",
        "# Jangan di commit ketika ada api_key nya, bakalan error di github\n",
        "api_key =\"YOUR_API_KEY\"\n",
        "openai.api_key = api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f08dd7",
      "metadata": {
        "id": "10f08dd7"
      },
      "source": [
        "# Create training data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "569f0c1f",
      "metadata": {
        "id": "569f0c1f"
      },
      "source": [
        "Make sure to end each `prompt` with a suffix. According to the [OpenAI API reference](https://beta.openai.com/docs/guides/fine-tuning \"fine-tuning reference\"), you can use ` ->`.\n",
        "\n",
        "Also, make sure to end each `completion` with a suffix as well; I'm using `.\\n`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5904b9",
      "metadata": {
        "id": "ca5904b9"
      },
      "outputs": [],
      "source": [
        "data_file = [\n",
        "    {\n",
        "        \"prompt\": \"Apa itu inflasi? ->\",\n",
        "        \"completion\": \"Inflasi adalah kenaikan harga barang dan jasa secara umum dan terus-menerus dalam suatu periode waktu tertentu.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Bagaimana cara mengatur anggaran bulanan? ->\",\n",
        "        \"completion\": \"Untuk mengatur anggaran bulanan, mulailah dengan mencatat semua pendapatan dan pengeluaran, kemudian buatlah kategori pengeluaran dan tetapkan batas pengeluaran untuk setiap kategori.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Apa itu saham? ->\",\n",
        "        \"completion\": \"Saham adalah bukti kepemilikan seseorang atau badan terhadap sebuah perusahaan. Dengan memiliki saham, investor berhak atas bagian dari keuntungan perusahaan tersebut.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Apa perbedaan antara saham dan obligasi? ->\",\n",
        "        \"completion\": \"Saham adalah surat berharga yang menunjukkan kepemilikan sebagian dari perusahaan, sedangkan obligasi adalah surat utang yang diterbitkan oleh perusahaan atau pemerintah sebagai bentuk pinjaman.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Bagaimana cara berinvestasi di pasar saham? ->\",\n",
        "        \"completion\": \"Untuk berinvestasi di pasar saham, Anda perlu membuka akun di perusahaan sekuritas, menyetor dana, dan mulai membeli saham melalui platform trading yang disediakan.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Apa itu diversifikasi investasi? ->\",\n",
        "        \"completion\": \"Diversifikasi investasi adalah strategi menyebar investasi ke berbagai jenis aset untuk mengurangi risiko. Dengan diversifikasi, kerugian pada satu aset dapat ditutupi oleh keuntungan dari aset lain.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Apa itu return on investment (ROI)? ->\",\n",
        "        \"completion\": \"Return on Investment (ROI) adalah rasio yang menunjukkan seberapa besar keuntungan yang diperoleh dari investasi dibandingkan dengan biaya investasi tersebut.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Bagaimana cara menghitung ROI? ->\",\n",
        "        \"completion\": \"ROI dapat dihitung dengan rumus: (Keuntungan dari investasi - Biaya investasi) / Biaya investasi x 100%.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Apa yang dimaksud dengan aset likuid? ->\",\n",
        "        \"completion\": \"Aset likuid adalah aset yang mudah dan cepat diubah menjadi uang tunai tanpa kehilangan nilai yang signifikan, seperti uang tunai dan rekening tabungan.\\n\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Apa itu risiko investasi? ->\",\n",
        "        \"completion\": \"Risiko investasi adalah kemungkinan bahwa hasil investasi akan berbeda dari yang diharapkan, termasuk kemungkinan kehilangan sebagian atau seluruh investasi.\\n\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e10cb45e",
      "metadata": {
        "id": "e10cb45e"
      },
      "source": [
        "# Save dict as JSONL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6ed465",
      "metadata": {
        "id": "7c6ed465"
      },
      "source": [
        "Training data need to be a JSONL document.\n",
        "JSONL file is a newline-delimited JSON file.\n",
        "More info about JSONL: https://jsonlines.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4bc0cf",
      "metadata": {
        "id": "4e4bc0cf"
      },
      "outputs": [],
      "source": [
        "file_name = \"training_data.jsonl\"\n",
        "\n",
        "with open(file_name, 'w') as outfile:\n",
        "    for entry in data_file:\n",
        "        json.dump(entry, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cbf169e",
      "metadata": {
        "id": "6cbf169e"
      },
      "source": [
        "# Check JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a5fe452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a5fe452",
        "outputId": "5d7def8c-9022-4c36-8684-f32494f38c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 10 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- All prompts end with suffix `? ->`\n",
            "- All completions end with suffix `.\\n`\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `training_data_prepared (2).jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"training_data_prepared (2).jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `? ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.58 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f training_data.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b923b02a",
      "metadata": {
        "id": "b923b02a"
      },
      "source": [
        "# Upload file to your OpenAI account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SP1odNLCpflh",
      "metadata": {
        "id": "SP1odNLCpflh"
      },
      "outputs": [],
      "source": [
        "# !pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDbpNTs4qiSt",
      "metadata": {
        "id": "hDbpNTs4qiSt"
      },
      "outputs": [],
      "source": [
        "upload_response = openai.File.create(\n",
        "  file=open(file_name, \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "upload_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NH8yQwGLqllP",
      "metadata": {
        "id": "NH8yQwGLqllP"
      },
      "outputs": [],
      "source": [
        "print(upload_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6f8267",
      "metadata": {
        "id": "fa6f8267"
      },
      "outputs": [],
      "source": [
        "# !upload_response = openai.File.create(\n",
        "#   file=open(file_name, \"rb\"),\n",
        "#   purpose='fine-tune'\n",
        "# )\n",
        "# upload_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20fb4254",
      "metadata": {
        "id": "20fb4254"
      },
      "source": [
        "# Save file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93469f37",
      "metadata": {
        "id": "93469f37"
      },
      "outputs": [],
      "source": [
        "file_id = upload_response.id\n",
        "file_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jcEeBWb2q7qX",
      "metadata": {
        "id": "jcEeBWb2q7qX"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1007a6",
      "metadata": {
        "id": "3e1007a6"
      },
      "source": [
        "# Fine-tune a model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e2da9b",
      "metadata": {
        "id": "57e2da9b"
      },
      "source": [
        "The default model is **Curie**.\n",
        "\n",
        "If you'd like to use **DaVinci** instead, then add it as a base model to fine-tune:\n",
        "\n",
        "```openai.FineTune.create(training_file=file_id, model=\"davinci\")```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16bb42a2",
      "metadata": {
        "id": "16bb42a2"
      },
      "outputs": [],
      "source": [
        "fine_tune_response = openai.FineTune.create(training_file=file_id)\n",
        "fine_tune_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2059b2b3",
      "metadata": {
        "id": "2059b2b3"
      },
      "source": [
        "# Check fine-tune progress"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc7fda90",
      "metadata": {
        "id": "cc7fda90"
      },
      "source": [
        "Check the progress with `openai.FineTune.list_events(id=fine_tune_response.id)` and get a list of all the fine-tuning events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf062ab",
      "metadata": {
        "id": "4cf062ab"
      },
      "outputs": [],
      "source": [
        "fine_tune_events = openai.FineTune.list_events(id=fine_tune_response.id)\n",
        "fine_tune_events"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362f5bf3",
      "metadata": {
        "id": "362f5bf3"
      },
      "source": [
        "Check the progress with `openai.FineTune.retrieve(id=fine_tune_response.id)` and get an object with the fine-tuning job data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01831be",
      "metadata": {
        "id": "f01831be"
      },
      "outputs": [],
      "source": [
        "retrieve_response = openai.FineTune.retrieve(id=fine_tune_response.id)\n",
        "retrieve_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e846ed",
      "metadata": {
        "id": "07e846ed"
      },
      "source": [
        "# Save fine-tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca86136",
      "metadata": {
        "id": "6ca86136"
      },
      "source": [
        "### Troubleshooting fine_tuned_model as null\n",
        "During the fine-tuning process, the **fine_tuned_model** key may not be immediately available in the fine_tune_response object returned by `openai.FineTune.create()`.\n",
        "\n",
        "To check the status of your fine-tuning process, you can call the `openai.FineTune.retrieve()` function and pass in the **fine_tune_response.id**. This function will return a JSON object with information about the training status, such as the current epoch, the current batch, the training loss, and the validation loss.\n",
        "\n",
        "After the fine-tuning process is complete, you can check the status of all your fine-tuned models by calling `openai.FineTune.list()`. This will list all of your fine-tunes and their current status.\n",
        "\n",
        "Once the fine-tuning process is complete, you can retrieve the fine_tuned_model key by calling the `openai.FineTune.retrieve()` function again and passing in the fine_tune_response.id. This will return a JSON object with the key fine_tuned_model and the ID of the fine-tuned model that you can use for further completions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a071cb90",
      "metadata": {
        "id": "a071cb90"
      },
      "source": [
        "### Option 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e7e760b",
      "metadata": {
        "id": "6e7e760b"
      },
      "source": [
        "If `fine_tune_response.fine_tuned_model != None` then the key **fine_tuned_model** is availble from the fine_tune_response object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0616dd72",
      "metadata": {
        "id": "0616dd72"
      },
      "outputs": [],
      "source": [
        "if fine_tune_response.fine_tuned_model != None:\n",
        "    fine_tuned_model = fine_tune_response.fine_tuned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34613188",
      "metadata": {
        "id": "34613188"
      },
      "source": [
        "### Option 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3635655e",
      "metadata": {
        "id": "3635655e"
      },
      "source": [
        "If `fine_tune_response.fine_tuned_model == None:` you can get the **fine_tuned_model** by listing all fine-tune events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d2f317",
      "metadata": {
        "id": "77d2f317"
      },
      "outputs": [],
      "source": [
        "if fine_tune_response.fine_tuned_model == None:\n",
        "    fine_tune_list = openai.FineTune.list()\n",
        "    fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619d0d25",
      "metadata": {
        "id": "619d0d25"
      },
      "source": [
        "### Option 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f13537bb",
      "metadata": {
        "id": "f13537bb"
      },
      "source": [
        "If `fine_tune_response.fine_tuned_model == None:` you can get the **fine_tuned_model** key by retrieving the fine-tune job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e6203b",
      "metadata": {
        "id": "35e6203b"
      },
      "outputs": [],
      "source": [
        "if fine_tune_response.fine_tuned_model == None:\n",
        "    fine_tuned_model = openai.FineTune.retrieve(id=fine_tune_response.id).fine_tuned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8601df11",
      "metadata": {
        "id": "8601df11"
      },
      "source": [
        "# Test the new model on a new prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c654268c",
      "metadata": {
        "id": "c654268c"
      },
      "source": [
        "Remember to end the prompt with the same suffix as we used in the training data; ` ->`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37cfb2da",
      "metadata": {
        "id": "37cfb2da"
      },
      "outputs": [],
      "source": [
        "new_prompt = \"NEW PROMPT ->\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee69cb8",
      "metadata": {
        "id": "bee69cb8"
      },
      "outputs": [],
      "source": [
        "answer = openai.Completion.create(\n",
        "  model=fine_tuned_model,\n",
        "  prompt=new_prompt,\n",
        "  max_tokens=10, # Change amount of tokens for longer completion\n",
        "  temperature=0\n",
        ")\n",
        "answer['choices'][0]['text']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
